{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoramic Images from Video\n",
    "# Completed by Lonnie Chien, Suraj Kalidindi\n",
    "# For this project, we created a Panorama picture generator. It takes in a video as input, and converts it into a panorama image using repeated image stitching. The input video is in the form of a \"panning shot,\" as it is called in film. This is a technique where the camera is in a fixed and central location, and camera person rotates their body to capture a video of the scene. We used our project 4 code as a starting point.\n",
    "\n",
    "# Where we got our videos from:\n",
    "\n",
    "# art: https://www.youtube.com/watch?v=V5tGanZR3XU\n",
    "\n",
    "# woman: https://www.youtube.com/watch?v=eBL6vu9NQtw\n",
    "\n",
    "# First, we want to process the video and get the images that we will later on stitch together. To do this, we first crop/resize the video to a window of a consistent size, to make it a bit easier to work with. Then, we break up the video into its individual frames to be extracted as images.\n",
    "\n",
    "# Even a short, 10-second video clip can have hundreds of frames. It is not necessary to use that many images to build the panorama, so instead we only need to keep every 20th, 30th, or Nth frame. How large N should be depends on a few factors: first, the quality of the video in terms of FPS (frames per second). If the video takes many frames per second, most of the frames will appear similar, so more of them can be thrown out. Second, the speed at which the camera is rotated. If the camera moves quickly, we will have to choose frames closer together so we don't lose features in the panorama.\n",
    "\n",
    "# To create a stitch, we used a stitching function that is similar to the one we created in Project 4. The function takes in two images, and a set of pixel coordinates (points) for matching features between the images. The stitcher function finds the homography that transforms the first set of points onto the other, warps the images, and superimposes them.\n",
    "\n",
    "# We used the SIFT detector perform the feature matching. The matching algorithm uses k nearest neighbors to find many matching points, then uses the ratio test to immediately filter out some of the bad matches. The ratio test works by matching keypoints between the first and second images, and finding the best matches for the keypoints. That is, the two nearest neighbors to the feature descriptor. It finds the difference using the ratio of distances, and if the distances are not different enough then the match is thrown out. We then use RANSAC (as it is implemented in Project 4) to further improve our set of matching points.\n",
    "\n",
    "# Matches are found and stitches are made iteratively. We begin by stitching together the first two images. Then, result image and the third image are stitched together. Then that result is stitched with the fourth image, and so on. After all images are stitched, the resulting image is a panorama. Finally, we can improve the result by warping it to even out some of the differing widths and heights that resulted from the stitches.\n",
    "\n",
    "# A challenge we faced in this project was getting quality matches from the feature detector. We started with ORB detector, but later found that SIFT works better. SIFT takes longer than ORB, so we had to downsample the dataset. We also found that indoor videos tended to work better than outdoor videos. This is because even after performing the ratio test and RANSAC on our matches, different trees or foliage just have similar features, which resulted in a lot of false positive matches. Another challenge was that the basic method for combining the warped images in the stitcher was creating dark shades in regions of the images as older parts of the images lost intensity (geometric sequence). The solution was by indexing the warped images with masking.\n",
    "\n",
    "# Our code follows:\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import sys, os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "Resize the video and extract the frames as images:\n",
    "\n",
    "\n",
    "def resize_video(input_filename, start=0, end=None):\n",
    "    \"\"\"Resize frames `start` to `end` of video `input_filename`\n",
    "    \n",
    "    Resizes to 640x480 (or smaller depending on aspect ratio).\n",
    "    \"\"\"\n",
    "    ##################################################\n",
    "    # get video properties\n",
    "\n",
    "    if not os.path.exists(input_filename):\n",
    "        print('error:', input_filename, 'does not exist')\n",
    "        sys.exit(1)\n",
    "\n",
    "    nframes, width, height, fps = get_num_frames(input_filename)\n",
    "\n",
    "    print(input_filename, 'has', nframes, \n",
    "          f'frames of size {width}x{height} at {fps} fps')\n",
    "\n",
    "    ##################################################\n",
    "    # compute output size\n",
    "\n",
    "    frac = 360.0/max(width, height)\n",
    "\n",
    "    if frac >= 1.0:\n",
    "        print('max dimension already <= 360, not resizing!')\n",
    "        sys.exit(1)\n",
    "\n",
    "    output_size = (int(round(width*frac)), int(round(height*frac)))\n",
    "\n",
    "    print('will resize to {}x{}'.format(*output_size))\n",
    "\n",
    "    ##################################################\n",
    "    # deal with start/end indices\n",
    "\n",
    "    if end is None:\n",
    "        end = nframes\n",
    "\n",
    "    if start < 0 or start > nframes or end < 0 or end > nframes or end < start:\n",
    "        print('invalid frame indices, must have 0 <= STARTFRAME < ENDFRAME <', nframes)\n",
    "        sys.exit(1)\n",
    "\n",
    "    if start > 0 or end < nframes:\n",
    "        print(f'will write frames {start}-{end}')\n",
    "        \n",
    "    ##################################################\n",
    "    # create the output video\n",
    "    path_prefix, basename = os.path.split(input_filename)\n",
    "    basename, _ = os.path.splitext(basename)\n",
    "\n",
    "    fourcc, ext = (cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 'mp4')\n",
    "    output_filename = os.path.join(path_prefix, basename + '_resized.' + ext)\n",
    "\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps, output_size)\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_filename)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            break\n",
    "        frame = cv2.resize(frame, output_size, interpolation=cv2.INTER_AREA)\n",
    "        if frame_idx >= start and frame_idx < end:\n",
    "            writer.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    print(f'wrote {end-start} frames to {output_filename}')\n",
    "\n",
    "def get_num_frames(input_filename):\n",
    "\n",
    "    cap = cv2.VideoCapture(input_filename)\n",
    "\n",
    "    # try the fast way\n",
    "    nframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    if not fps > 1:\n",
    "        # fps buggy sometimes\n",
    "        fps = 30.0 \n",
    "\n",
    "    if nframes > 1 and width > 1 and height > 1:\n",
    "        # it worked\n",
    "        return int(nframes), int(width), int(height), fps\n",
    "\n",
    "    # the slow way\n",
    "    cnt = 0\n",
    "    \n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            break\n",
    "        height, width = frame.shape[:2]\n",
    "        cnt += 1\n",
    "\n",
    "    return cnt, width, height, fps\n",
    "# The following function is useful for warping our results at the end:\n",
    "\n",
    "def t_homog(image, i, j, m):\n",
    "\n",
    "    # Load an image\n",
    "    orig = image.copy()\n",
    "\n",
    "    # Get its size \n",
    "    h, w = orig.shape[:2]\n",
    "    size = (w, h)\n",
    "\n",
    "    ######################################################################\n",
    "    # Now make a neat \"keystone\" type homography by composing a\n",
    "    # translation, a simple homography, and the inverse translation.\n",
    "\n",
    "    # Translate center of image to (0,0)\n",
    "    Tfwd = np.eye(3)\n",
    "    Tfwd[0,2] = -0.5 * w\n",
    "    Tfwd[1,2] = -0.5 * h\n",
    "\n",
    "    # Get inverse of that\n",
    "    Tinv = np.linalg.inv(Tfwd)\n",
    "    # marker\n",
    "    # Homography that decreases homogeneous \"w\" coordinate with increasing\n",
    "    # depth so bottom rows appear \"closer\" than top rows\".\n",
    "    H = np.eye(3)\n",
    "    H[i,j] = m\n",
    "\n",
    "    S = np.eye(3)\n",
    "    S[0,0] = 0.5\n",
    "    S[1,1] = 0.5\n",
    "\n",
    "    # Compose the three transforms together using matrix\n",
    "    # multiplication. \n",
    "    #\n",
    "    # Use @ operator to do matrix multiplication on numpy arrays\n",
    "    # (remember * gives element-wise product)\n",
    "\n",
    "    H = S @ Tinv @ H @ Tfwd\n",
    "\n",
    "    ######################################################################\n",
    "    # Now translate the final warped image so we can see it all. This uses\n",
    "    # the same trick from transrot.py, except instead of modifying the\n",
    "    # homography matrix directly, just composes it with a translation.\n",
    "\n",
    "    # Get corner points of original image - note this is shaped as an\n",
    "    # n-by-1-by-2 array, because that's what cv2.perspectiveTransform\n",
    "    # expects. If you have a more typical n-by-2 array, you can use\n",
    "    # numpy's reshape method to get it into the correct shape.\n",
    "    p = np.array( [ [[0, 0]],\n",
    "                    [[w, 0]],\n",
    "                    [[w, h]],\n",
    "                    [[0, h]] ], dtype='float32' )\n",
    "\n",
    "    # Map through warp\n",
    "    pp = cv2.perspectiveTransform(p, H)\n",
    "\n",
    "    # Get integer bounding box of form (x0, y0, width, height)\n",
    "    box = cv2.boundingRect(pp)\n",
    "\n",
    "    # Separate into dimensions and origin\n",
    "    dims = box[2:4]\n",
    "    p0 = box[0:2]\n",
    "\n",
    "    # Create translation transformation to shift image\n",
    "    Tnice = np.eye(3)\n",
    "    Tnice[0,2] -= p0[0]\n",
    "    Tnice[1,2] -= p0[1]\n",
    "\n",
    "    # Compose them via matrix multiplication\n",
    "    Hnice = Tnice @ H\n",
    "\n",
    "    # Show it\n",
    "    warpedNice = cv2.warpPerspective(orig, Hnice, dims)\n",
    "    return warpedNice\n",
    "# The stitcher function finds the homography that transforms the first set of points onto the other, warps the images, and superimposes them.\n",
    "\n",
    "def stitcher(img1, pts1, img2, pts2):\n",
    "\n",
    "    \"\"\"Stitches img1 and img2 into a single image using correspondences\n",
    "    Inputs:\n",
    "        img1, img2 - 2d np.array (np.uint8), of the images to stitch together\n",
    "        pts1, pts2 - 2d np.array (np.float32, size 2 by n), of the points to stitch together. Each\n",
    "                     row in pts1 corresponds to the same row in pts2\n",
    "    Returns:\n",
    "        result - 2d np.array (np.uint8) of warped image (properly cropped). \n",
    "    \"\"\"\n",
    "\n",
    "    pts1 = pts1.reshape((len(pts1),1,2))\n",
    "    pts2 = pts2.reshape((len(pts2),1,2))\n",
    "\n",
    "    h,w,c = img1.shape\n",
    "    h2, w2, c2 = img2.shape\n",
    "\n",
    "    # find homography\n",
    "    borderPoints1 = np.array([[0,0],[w,0],[w,h],[0,h]]).reshape((4,1,2))\n",
    "    borderPoints1 = borderPoints1.astype(np.float32)\n",
    "    borderPoints2 = np.array([[0,0],[w2,0],[w2,h2],[0,h2]]).reshape((4,1,2))\n",
    "    borderPoints2 = borderPoints2.astype(np.float32)\n",
    "  \n",
    "    H, mask = cv2.findHomography(pts1,pts2)\n",
    "    #p_trans = cv2.perspectiveTransform(pts1,H)\n",
    "    borderPoints1_warped = cv2.perspectiveTransform(borderPoints1,H)\n",
    "\n",
    "    allpts = np.concatenate((borderPoints1_warped,borderPoints2)).reshape(-1,2)\n",
    "    allpts = allpts.astype(np.float32)\n",
    "\n",
    "    # use boundingrect to get x0, y0\n",
    "\n",
    "    x0,y0,w_br,h_br = cv2.boundingRect(allpts)\n",
    "    \n",
    "    # construct T\n",
    "    T = np.eye(3,3,dtype='float32')\n",
    "    T[0,2] -= x0\n",
    "    T[1,2] -= y0\n",
    "\n",
    "\n",
    "    # get M matrix M = T@H\n",
    "    M = T @ H\n",
    "\n",
    "    # Warp A&M, B&T\n",
    "\n",
    "    img1_resized = np.pad(img1,[(0,h_br - h),(0,w_br - w),(0,0)])\n",
    "    img2_resized = np.pad(img2,[(0,h_br - h2),(0,w_br - w2),(0,0)])\n",
    "    \n",
    "    warpA = cv2.warpPerspective(img1_resized,M,(w_br,h_br))\n",
    "    warpB = cv2.warpPerspective(img2_resized,T,(w_br,h_br))\n",
    "\n",
    "    # combine warped images \n",
    "    \n",
    "    m1 = ma.make_mask(warpA)\n",
    "    m2 = ma.make_mask(warpB)\n",
    "\n",
    "    m3 = np.logical_and(m1,m2)\n",
    "    combined_img = np.zeros_like(warpA)\n",
    "    \n",
    "    combined_img[m1] = warpA[m1]\n",
    "    combined_img[m2] = warpB[m2]\n",
    "    combined_img[m3] = warpA[m3]//2 + warpB[m3]//2\n",
    "\n",
    "    #Reversing warp\n",
    "    \n",
    "    return combined_img.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RANSAC algorithm:\n",
    "\n",
    "def ransac_homography(pts1, pts2, Nmax=1000, thresh=3):\n",
    "    \"\"\"Finds homography between pts1 and pts2 using RANSAC\n",
    "    Inputs:\n",
    "        pts1, pts2 - 2d np.array (np.float32, size 2 by n), of the points to stitch together. Each\n",
    "                     row in pts1 corresponds to the same row in pts2. It may contain outliers.\n",
    "        Nmax - int, maximum number of iterations (default 1000)\n",
    "        thresh - float, threshold for accepting inlier (default 3)\n",
    "    Returns:\n",
    "        inliers - list of indices to rows of valid points\n",
    "    \"\"\"\n",
    "\n",
    "    largest = [0]\n",
    "    pts1 = pts1.reshape((len(pts1),1,2))\n",
    "    pts2 = pts2.reshape((len(pts2),1,2))\n",
    "\n",
    "    for i in range(Nmax):\n",
    "        # select 4 random rows in pts1, pts2\n",
    "        random_points =  random.sample(range(len(pts1)),4)\n",
    "\n",
    "        # find homography b/t those points\n",
    "     \n",
    "        rand_pts1 = pts1[random_points,:]\n",
    "        rand_pts2 = pts2[random_points,:]\n",
    "\n",
    "        rand_pts1 = rand_pts1.reshape((4,1,2))\n",
    "        rand_pts2 = rand_pts2.reshape((4,1,2))\n",
    "\n",
    "            \n",
    "        H, mask = cv2.findHomography(rand_pts1,rand_pts2)\n",
    "        # Warp pts1 to pts2_est using this homography (using cv2.perspectiveTransform)\n",
    "        pts2_est = cv2.perspectiveTransform(pts1,H)\n",
    "        # Find all rows where pts2_est and pts2 are within thresh distance.\n",
    "        inliers = []\n",
    "        pts2 = pts2.reshape((len(pts2),2))\n",
    "        pts2_est = pts2_est.reshape((len(pts2),2))\n",
    "        for k in range(len(pts2)):\n",
    "            #Finding euclidean distance between pts2 and pts2_est\n",
    "        \n",
    "            dist = ((pts2[k][0]-pts2_est[k][0])**2+(pts2[k][1]-pts2_est[k][1])**2)**0.5\n",
    "            if dist <= thresh:\n",
    "                inliers.append(k)\n",
    "        \n",
    "        # save largest inlier\n",
    "        if len(inliers) > len(largest):\n",
    "            largest = inliers \n",
    "        \n",
    "        \n",
    "    return largest \n",
    "# The SIFT detector to find matches between two images, perform the ratio test, and return the sets of \"good\" points.\n",
    "\n",
    "def get_points(img1, img2):\n",
    "    '''\n",
    "     gets matching points of two images\n",
    "    Inputs:\n",
    "        img1, img2\n",
    "    Returns:\n",
    "        pts1_ransac,pts2_ransac - lists of matching points for each image\n",
    "    '''\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "  \n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    corners_1,des1 = sift.detectAndCompute(gray1,None)\n",
    "    corners_2,des2 = sift.detectAndCompute(gray2,None)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches_all = bf.knnMatch(des1,des2,k=2)\n",
    " \n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    #Finding good matches\n",
    "    matches = []\n",
    "    for m,n in matches_all:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            matches.append([m])\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "\n",
    "        (x1,y1) = corners_1[matches[i][0].queryIdx].pt\n",
    "        (x2,y2) = corners_2[matches[i][0].trainIdx].pt\n",
    "\n",
    "        pts1.append([x1,y1])\n",
    "        pts2.append([x2,y2])\n",
    "\n",
    "    \n",
    "    pts1 = np.array(pts1,dtype=np.float32)\n",
    "    pts2 = np.array(pts2,dtype=np.float32)\n",
    "\n",
    "    inliers = ransac_homography(pts1, pts2, Nmax=500, thresh=5)\n",
    "    pts1_ransac = pts1[inliers,:]\n",
    "    pts2_ransac = pts2[inliers,:]\n",
    "    \n",
    "  \n",
    "    return pts1_ransac, pts2_ransac\n",
    "\n",
    "\n",
    "# These are some main functions that make everything work in order:\n",
    "\n",
    "def videoToFrames(video_file,N = 55):\n",
    "    \"\"\"Converts Video to a list of frames\n",
    "    Inputs:\n",
    "        video_file\n",
    "        N - number of frames required in video \n",
    "    Returns:\n",
    "        images - list of frames\n",
    "    \"\"\"\n",
    "    resize_video(video_file)\n",
    "    \n",
    "    # get frames out of resized video\n",
    "    vidcap = cv2.VideoCapture(video_file)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "\n",
    "    while success:\n",
    "        cv2.imwrite(\"/work/Frames/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    # write each Nth frame into images list\n",
    "    images = []\n",
    "    for i in range(count//N):\n",
    "        img_path = '/work/Frames/frame%d.jpg' % (i*N)\n",
    "        img_selected = cv2.cvtColor(cv2.imread(img_path),cv2.COLOR_BGR2RGB)\n",
    "        images.append(img_selected[::4,::4])\n",
    "    return images\n",
    "\n",
    "\n",
    "def makePano(images):\n",
    "    \"\"\"\n",
    "    Makes the Panorama image\n",
    "    Inputs:\n",
    "        images - list of images to stitch together\n",
    "    Returns:\n",
    "        imgNew - Panorama image\n",
    "    \"\"\"\n",
    "\n",
    "    imgNew = images[0]\n",
    "    fig = plt.figure(figsize = (10,7))\n",
    "    for i in range(len(images)-1):\n",
    "     \n",
    "        start = time.perf_counter()\n",
    "        pts1,pts2 = get_points(imgNew,images[i+1])\n",
    "\n",
    "        imgStitch = stitcher(imgNew,pts1,images[i+1],pts2)\n",
    "        imgNew = imgStitch\n",
    "    \n",
    "        fig.add_subplot(int((len(images)-1)/3)+int((len(images)-1)%3>0),3,i+1)\n",
    "        plt.imshow(imgNew)\n",
    "    \n",
    "    return imgNew\n",
    "    \n",
    "# The following code displays the new image after each stitch\n",
    "\n",
    "\n",
    "# /work/input video/woman.mp4 has 458 frames of size 1280x720 at 25.0 fps\n",
    "# will resize to 360x202\n",
    "# wrote 458 frames to /work/input video/woman_resized.mp4\n",
    "\n",
    "\n",
    "\n",
    "video_file = \"/work/input video/art.mp4\"\n",
    "images = videoToFrames(video_file,N = 20) # if run out of memory, increase value of N here\n",
    "finalImage = makePano(images)\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.imshow(finalImage)\n",
    "# /work/input video/art.mp4 has 253 frames of size 1280x720 at 29.0 fps\n",
    "# will resize to 360x202\n",
    "# wrote 253 frames to /work/input video/art_resized.mp4\n",
    "\n",
    "\n",
    "\n",
    "# The strange warping of this image is due to the change in depth during the video (video starts from bottom of the wall, which is close, and goes further away to the top-right of the wall). To potentially fix this, we would need to find the corners of the panorama picture without the zero-padded pixels, and use those four points along with the four corner points of the bounding rectangle to create a homography matrix similar to how we did in the stitcher function.\n",
    "\n",
    "art_warp = t_homog(finalImage,2,1,0.0005)\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.imshow(art_warp)\n",
    "\n",
    "\n",
    "# Final image written to output file\n",
    "\n",
    "art_output = cv2.cvtColor(art_warp, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('/work/output panoramas/art_output.jpg',art_output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
